{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The goals of this analysis is to generate in silico random input sequences for different simulations using BPNet and ChromBPNet.\n",
    "\n",
    "# Computational setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-29 19:22:37.346158: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/lib/nccl/cuda:/usr/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/lib/nccl/cuda:\n",
      "2023-09-29 19:22:37.346188: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "#Packages\n",
    "import os\n",
    "import sys\n",
    "import keras\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import glob\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "from tqdm import tqdm\n",
    "\n",
    "import plotnine\n",
    "from plotnine import *\n",
    "\n",
    "# Settings\n",
    "\n",
    "## Working options\n",
    "os.chdir(f'/n/projects/mw2098/analysis/acc_vs_bind/_bpreveal_version/')\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "## Custom functions\n",
    "sys.path.insert(0, f'/n/projects/mw2098/shared_code/bpreveal/functions/')\n",
    "from perturb import generate_random_seq\n",
    "from functional import one_hot_encode_sequences, one_hot_encode_sequence, one_hot_decode_sequence, shuffle_seqs\n",
    "from motifs import extract_seqs_from_df, resize_coordinates\n",
    "\n",
    "# from functional import shuffle_seqs, one_hot_encode_sequence, one_hot_encode_sequences, \\\n",
    "#     one_hot_decode_sequence, insert_motif, logitsToProfile\n",
    "\n",
    "sys.path.insert(0, f'/home/mw2098/bin/bpreveal/src')\n",
    "import losses\n",
    "\n",
    "## Custom variables\n",
    "figure_path = 'figures/7_generate_insilico_trials'\n",
    "genome = '/n/projects/mw2098/genomes/mm10/mm10.fa'\n",
    "regions_1based_path = 'tsv/mapped_motifs/all_islands_curated_1based_w_experimental_data.tsv.gz'\n",
    "regions_0based_path = 'bed/mapped_motifs/all_islands_curated_0based_sized_to_output.bed'\n",
    "\n",
    "motif_to_task_dict = {'Oct4-Sox2': 'oct4', \n",
    "                      'Oct4': 'oct4',\n",
    "                      'Sox2': 'sox2',\n",
    "                      'Klf4': 'klf4',\n",
    "                      'Zic3': 'zic3',\n",
    "                      'Nanog': 'nanog'}\n",
    "\n",
    "acc_vs_bind_dict = {'acc': {'input_length': 2114, \n",
    "                            'trials': 256, \n",
    "                            'model_dir': 'models/ATAC_fold1_residual.model',\n",
    "                            'tasks': ['atac']},\n",
    "                    'bind': {'input_length': 3056, \n",
    "                             'trials': 256,\n",
    "                             'model_dir': 'models/OSKNZ_fold1.model',\n",
    "                             'tasks': ['oct4', 'sox2', 'klf4', 'nanog', 'zic3']}\n",
    "                   }\n",
    "\n",
    "output_length = 1000\n",
    "seed = 2356\n",
    "\n",
    "## Filesystem commands\n",
    "!mkdir -p npz {figure_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import mapped motif sequences\n",
    "\n",
    "Here, we will collect motif sequences that result in dominantly meaningful contribution for binding and accessibility. We will set a threshold by which if a motif sequence maps above a certain contribution for binding or accessibility, it will be blacklisted for all randomly generated sequences. \n",
    "\n",
    "Because of the prevalence of motif sequences, we will have to select a high threshold. This filtering is simply done in order to ensure that the best motifs are absent, in order to reduce the outlier predictions in addition to averaging across many trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# motifs_df = pd.read_csv(motifs_path, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def quantile_func(x, quantile = .99): return np.quantile(x, quantile)\n",
    "# quantiles_df = motifs_df[['motif', 'seq', 'bind_contrib', 'acc_contrib']].groupby(['motif']).agg(quantile_func).reset_index()\n",
    "# quantiles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blacklisted_seqs = np.array([])\n",
    "# for i,row in quantiles_df.iterrows():\n",
    "#     s = motifs_df[(motifs_df.motif==row.motif) & \\\n",
    "#               (motifs_df.bind_contrib>row.bind_contrib) & \\\n",
    "#               (motifs_df.acc_contrib>row.acc_contrib)].seq.values\n",
    "#     blacklisted_seqs = np.append(blacklisted_seqs, s)\n",
    "# blacklisted_seqs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate sequences with varying CG-content and CpG-ratios\n",
    "\n",
    "Here, we will set up a case that generates random sequences. The random sequence will be kept if we:\n",
    "\n",
    "+ vary CG-content\n",
    "+ check for desired CpG island enrichment\n",
    "+ keep if sequences don't contain blacklisted feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to calculate CpG ratios\n",
    "\n",
    "CpG density was manually calculated based on the 2006 publication that originated this particular density function (https://www.pnas.org/doi/full/10.1073/pnas.0510310103)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cpg_ratio(C_counts, G_counts, CpG_counts, region_width = 1000):\n",
    "    cpg_ratio = CpG_counts / ((((C_counts + G_counts)/2)**2)/region_width)\n",
    "    cpg_ratio = np.round(cpg_ratio,2)\n",
    "    return(cpg_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define scope of generated random sequences\n",
    "\n",
    "What levels of CpG ratios and GC contents do we want to consider when comparing differences? We will select a linear gradient of increasing GC content and CpG ratios since the relationship is linked between these two features. \n",
    "\n",
    "First, we will briefly summarize data to examine GC content and how it relates to CpG ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_df = pd.read_csv(regions_1based_path, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_df['GC_content'] = (regions_df['C'] + regions_df['G'])/1000\n",
    "gc_vs_cpg_df = regions_df[['CpG_ratio', 'GC_content']].groupby('CpG_ratio').median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotnine.options.figure_size = (6, 3)\n",
    "gc_vs_cpg_plot = (ggplot(data = gc_vs_cpg_df, mapping = aes(x = 'GC_content', y = 'CpG_ratio'))+\n",
    "    geom_point()+\n",
    "    theme_classic()\n",
    ")\n",
    "gc_vs_cpg_plot\n",
    "gc_vs_cpg_plot.save(f'{figure_path}/GC_vs_CpG.png')\n",
    "gc_vs_cpg_plot.save(f'{figure_path}/GC_vs_CpG.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see that the CpG ratio depends on the GC content of the sequences. Given the distribution across the genome in `6*.Rmd`, and the above summarization, we will select 4 levels of CpG ratio/GC content features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CpG_ratio_lower</th>\n",
       "      <th>CpG_ratio_upper</th>\n",
       "      <th>GC_content</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.45</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.6</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CpG_ratio_lower CpG_ratio_upper GC_content  group_id\n",
       "0               0             0.2        0.4       low\n",
       "1             0.2            0.25       0.45  baseline\n",
       "2            0.25             0.6        0.5       mid\n",
       "3             0.6            1.25        0.6      high"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composition_df = pd.DataFrame([[0, .2, .25, .6], [.2, .25, .6, 1.25], [.4, .45, .5, .6], ['low', 'baseline', 'mid', 'high']]).transpose()\n",
    "composition_df.columns = ['CpG_ratio_lower', 'CpG_ratio_upper', 'GC_content', 'group_id']\n",
    "composition_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "composition_df.to_csv('npz/random_seq_composition.tsv', index = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate random sequences based on GC content and CpG ratios\n",
    "\n",
    "We previously tried to generate these sequences truly randomly, but then the GC and CpG features would not agree. There was large incompatibility with getting the above plot relationship to work, so clearly there is a design in base genomic composition that extends beyond \"random allocation of nucleotides\". Because of this, and because the model was trained with these in vivo sequences and not random sequences, we chose to generate our random set by selecting a random island and shuffling that island. We iterate through different islands until they match our criteria and then save them to our arrays.\n",
    "\n",
    "First, we want to define our \"tolerance threshold\" for the GC content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "GC_content_threshold = .025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to loop through these desired criteria. For each iteration, a sequence needs to:\n",
    "+ match GC content\n",
    "+ match CpG content\n",
    "+ be derived from a region sequence that is shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq length 2563056 ,  0.4 ,  0\n",
      "Seq length 2563056 ,  0.45 ,  0.2\n",
      "Seq length 2563056 ,  0.5 ,  0.25\n",
      "Seq length 2563056 ,  0.6 ,  0.6\n"
     ]
    }
   ],
   "source": [
    "# %%script false --no-raise-error\n",
    "for k,v in acc_vs_bind_dict.items():\n",
    "    input_length = v['input_length']\n",
    "    trials = v['trials']\n",
    "    \n",
    "    #Extract in vivo sequences\n",
    "    regions_0based_df = pd.read_csv(regions_0based_path, sep='\\t', header=None, \n",
    "                                    names=['chrom', 'start', 'end', 'name', 'score', 'strand'])\n",
    "    regions_0based_df = resize_coordinates(regions_0based_df, width = input_length, fix = 'center')\n",
    "    region_seqs = extract_seqs_from_df(coords_df = regions_0based_df, \n",
    "                                       fasta_path = genome, \n",
    "                                       chrom_column = 'chrom', \n",
    "                                       start_column = 'start', \n",
    "                                       end_column = 'end')\n",
    "\n",
    "    for i,row in composition_df.iterrows():\n",
    "        np.random.seed(seed)\n",
    "        gc = row['GC_content']\n",
    "        group_id = row['group_id']\n",
    "        \n",
    "        ACGT_weights = [(1-gc)/2, gc/2, gc/2, (1-gc)/2]\n",
    "        cpg_min = row['CpG_ratio_lower']\n",
    "        cpg_max = row['CpG_ratio_upper']\n",
    "        \n",
    "        npz_path = f'npz/random_seqs_seed_{seed}_input_{input_length}_trials_{trials}_group_{group_id}_gc_{gc}_cpg_{cpg_min}_to_{cpg_max}_array.npz'\n",
    "        \n",
    "        if not os.path.exists(npz_path):\n",
    "            seqs = []\n",
    "            while len(seqs)<trials:\n",
    "\n",
    "                #Shuffle a randomly selected sequence and see if it satisfies criteria\n",
    "                seq_1he = one_hot_encode_sequence(np.random.choice(region_seqs, 1)[0])\n",
    "                shuffle_1he = shuffle_seqs(seq_1he, num_shufs=1, k=2)[0]\n",
    "\n",
    "                candidate_seq = one_hot_decode_sequence(shuffle_1he)\n",
    "                C_counts = candidate_seq.count('C')\n",
    "                G_counts = candidate_seq.count('G')\n",
    "                GC_content = (C_counts + G_counts)/input_length\n",
    "                gc_match = (GC_content >= (gc - GC_content_threshold)) & (GC_content <= (gc + GC_content_threshold))\n",
    "\n",
    "                CpG_counts = candidate_seq.count('CG')\n",
    "                cpg_ratio = calculate_cpg_ratio(C_counts = C_counts, G_counts = G_counts, \n",
    "                                                CpG_counts = CpG_counts, region_width = input_length)\n",
    "                cpg_match = (cpg_ratio>=cpg_min) & (cpg_ratio <= cpg_max)\n",
    "\n",
    "    #             Keep sequence if the large and small window both match CpG and CG levels within a certain tolerance\n",
    "    #             This approach maintains same sequences across trials.\n",
    "    #             if (not any(s in candidate_seq for s in blacklisted_seqs)) & cpg_match :\n",
    "                if cpg_match & gc_match:\n",
    "                    seqs = seqs + [candidate_seq]\n",
    "                    seqs = list(set(seqs)) #In case an identical sequence gets picked.\n",
    "                    sys.stdout.write(\"\\rSeq length %i\" % len(seqs))\n",
    "                    sys.stdout.flush()\n",
    "            seqs_1he = one_hot_encode_sequences(seqs)\n",
    "            np.savez(npz_path, seqs_1he = seqs_1he)\n",
    "            print(input_length, ', ', gc, ', ', cpg_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline prediction levels of these random sequences will be visualized in later analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does bias model understand CpG content?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['npz/random_seqs_seed_2356_input_2114_trials_256_group_mid_gc_0.5_cpg_0.25_to_0.6_array.npz',\n",
       " 'npz/random_seqs_seed_2356_input_2114_trials_256_group_baseline_gc_0.45_cpg_0.2_to_0.25_array.npz',\n",
       " 'npz/random_seqs_seed_2356_input_2114_trials_256_group_low_gc_0.4_cpg_0_to_0.2_array.npz',\n",
       " 'npz/random_seqs_seed_2356_input_2114_trials_256_group_high_gc_0.6_cpg_0.6_to_1.25_array.npz']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npz_paths = glob.glob(f'npz/*input_2114_*')\n",
    "npz_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-30 00:43:33.406533: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/lib/nccl/cuda:/usr/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/lib/nccl/cuda:\n",
      "2023-09-30 00:43:33.406607: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-09-30 00:43:33.406644: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cerebro211): /proc/driver/nvidia/version does not exist\n",
      "2023-09-30 00:43:33.407091: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "acc_model = load_model(acc_vs_bind_dict['acc']['model_dir'], custom_objects = {'multinomialNll' : losses.multinomialNll})\n",
    "bias_model = load_model('models/Tn5_bias.model', custom_objects = {'multinomialNll' : losses.multinomialNll})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_flank = (acc_vs_bind_dict['acc']['input_length'] - bias_model.input.shape[1])/2\n",
    "int(bias_flank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "preds_df = pd.DataFrame()\n",
    "for group in composition_df.group_id.values:\n",
    "    acc_seqs = np.load(glob.glob(f'npz/random_seqs_seed_2356_input_2114_trials_256_group_{group}*_array.npz')[0])['seqs_1he']\n",
    "    bias_seqs = acc_seqs[:, int(bias_flank):(int(bias_flank) + int(bias_model.input.shape[1])), :]\n",
    "    \n",
    "    #Predict null accessibility\n",
    "    acc_null_preds_raw_arr = acc_model.predict(acc_seqs)\n",
    "    bias_null_preds_raw_arr = bias_model.predict(bias_seqs)\n",
    "    \n",
    "    #Extract log counts\n",
    "    df = pd.DataFrame(np.exp(np.squeeze(np.array([acc_null_preds_raw_arr[1], bias_null_preds_raw_arr[1]])))).transpose()\n",
    "    df.columns = ['acc', 'bias']\n",
    "    df['trials'] = list(range(acc_vs_bind_dict['acc']['trials']))\n",
    "    df['group'] = group\n",
    "    \n",
    "    preds_df = pd.concat([preds_df, df])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>bias</th>\n",
       "      <th>trials</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>476.319611</td>\n",
       "      <td>71.269142</td>\n",
       "      <td>127.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>2071.205322</td>\n",
       "      <td>109.577942</td>\n",
       "      <td>127.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>283.428284</td>\n",
       "      <td>57.814301</td>\n",
       "      <td>127.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mid</th>\n",
       "      <td>724.937744</td>\n",
       "      <td>85.029968</td>\n",
       "      <td>127.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  acc        bias  trials\n",
       "group                                    \n",
       "baseline   476.319611   71.269142   127.5\n",
       "high      2071.205322  109.577942   127.5\n",
       "low        283.428284   57.814301   127.5\n",
       "mid        724.937744   85.029968   127.5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df.groupby('group').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.307687478360486"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2071.205322/283.428284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8953431954491673"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "109.577942/57.814301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bpreveal",
   "language": "python",
   "name": "bpreveal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
